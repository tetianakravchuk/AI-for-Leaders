{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0392320-e3f8-4e08-a7f2-373d91054cae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48a74b5e-5180-4544-86a0-b047a877eb8e",
   "metadata": {},
   "source": [
    "# Week 1 - Preprocessing\n",
    "\n",
    "## Please run the cells of the notebook as you get to them while reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c24f12c-b364-40f0-b295-7c1ba88be680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c513ee-9d2b-408f-bbcd-33fa70a299e8",
   "metadata": {},
   "source": [
    "# 1. Lesson on how to search for Python commands\n",
    "\n",
    "Let's consider a few possible ways to learn about Python programming.  Let's suppose you want to learn how to produce a short summary of the information in your DataFrame.\n",
    "\n",
    "1. Your **instructor** could provide the information.\n",
    "\n",
    "You could be provided with a lesson about functions like info() and describe().  If you have a pandas DataFrame called df, then you can summarize its contents using df.info() or df.describe().  df.info() provides a list of column names with their counts and data types.  df.describe() will provide information such as the mean, min, max, standard deviation, and quantiles.  Thus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "33d97ef1-f92d-45a1-89e6-efea4d42ba75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A       4 non-null      int64\n",
      " 1   B       4 non-null      int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 196.0 bytes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A       4 non-null      int64\n",
      " 1   B       4 non-null      int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 196.0 bytes\n",
      "None\n",
      "              A         B\n",
      "count  4.000000  4.000000\n",
      "mean   2.500000  5.500000\n",
      "std    1.290994  1.290994\n",
      "min    1.000000  4.000000\n",
      "25%    1.750000  4.750000\n",
      "50%    2.500000  5.500000\n",
      "75%    3.250000  6.250000\n",
      "max    4.000000  7.000000\n",
      "   A  B\n",
      "0  1  4\n",
      "1  2  5\n",
      "2  3  6\n",
      "3  4  7\n",
      "Shape: (4, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Each inner list represents a single row of the DataFrame\n",
    "df = pd.DataFrame([[1, 4], [2, 5], [3, 6], [4, 7]], columns = ['A', 'B'])\n",
    "df.describe()\n",
    "df.info()\n",
    "df.head()\n",
    "df.shape\n",
    "df.columns\n",
    "df.dtypes\n",
    "\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(df.head())\n",
    "print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6541ee48-fb69-40d5-8b39-8f1b02918a9e",
   "metadata": {},
   "source": [
    "In this describe() result, we see that the two columns A and B each have four elements.  The means and other statistics are shown.\n",
    "\n",
    "2. You could look up the information on **Google**.\n",
    "\n",
    "If I Google the question \"how do I briefly summarize the contents of a dataframe using Python,\" I receive the following link (among others), which discusses the describe() command mentioned above:\n",
    "\n",
    "https://www.w3schools.com/python/pandas/ref_df_describe.asp\n",
    "\n",
    "It also provide the complete usage information:\n",
    "\n",
    "dataframe.describe(percentiles, include, exclude, datetime_is_numeric)\n",
    "\n",
    "It explains that \"percentiles\" is set by default to [0.25, 0.5, 0.75] but we could change that.  Let's try it!  Since there are three intervals here rather than four, it might be more meaningful to ask about a 33rd and 67th percentile rather than 25, 50, and 75.  We can use 1/3 for 0.33 and 2/3 for 0.67 to get the exact percentile values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "3aea76dd-f492-4bbe-9431-8e1a41cf0db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.290994</td>\n",
       "      <td>1.290994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33.3%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66.7%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A         B\n",
       "count  4.000000  4.000000\n",
       "mean   2.500000  5.500000\n",
       "std    1.290994  1.290994\n",
       "min    1.000000  4.000000\n",
       "33.3%  2.000000  5.000000\n",
       "50%    2.500000  5.500000\n",
       "66.7%  3.000000  6.000000\n",
       "max    4.000000  7.000000"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([[1, 4], [2, 5], [3, 6], [4, 7]], columns = ['A', 'B'])\n",
    "df.describe(percentiles = [1/3, 2/3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab1a7d0",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\">1. Studying notes</span>**\n",
    "\n",
    "count = how many values in the columns. There are 4 values.\n",
    "\n",
    "mean = average = sum/how many values\n",
    "\n",
    "$ \\text{Std} = \\sqrt{\\frac{\\sum (x_i - \\text{Mean})^2}{n}} $.\n",
    "\n",
    "### Explanation of Terms\n",
    "\\[\n",
    "\\begin{aligned}\n",
    "&\\bullet \\ x_i : \\text{Each value in the dataset.} \\\\\n",
    "&\\bullet \\ \\text{Mean} : \\text{The arithmetic mean of the dataset.} \\\\\n",
    "&\\bullet \\ n : \\text{The total number of data points.} \\\\\n",
    "&\\bullet \\ (x_i - \\text{Mean})^2 : \\text{The squared deviation of each value from the mean.}\n",
    "\\end{aligned}\n",
    "\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd06ce3-edf9-4786-982d-5650fc22ca58",
   "metadata": {},
   "source": [
    "Apparently, the 50% value (the median) stays even though we did not specifically request it.\n",
    "\n",
    "3. You could look up the official **documentation**.\n",
    "\n",
    "Now that we know we want the pandas describe() function, try Googling: pandas documentation describe.\n",
    "\n",
    "Here is the general documentation page for pandas:\n",
    "\n",
    "https://pandas.pydata.org/docs/index.html\n",
    "\n",
    "Here is the specific page for the describe() function:\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html\n",
    "\n",
    "When I look at this, it appears to be showing the most recent (currently 2.2) version of pandas; this is shown in the upper right corner.\n",
    "\n",
    "4. You could also ask **ChatGPT**.\n",
    "\n",
    "Let's try it.  ChatGPT, \"how do I briefly summarize the contents of a dataframe using Python\"\n",
    "\n",
    "When I do this, ChatGPT mentions describe() among other options, but does not go into detail.  However, I could ask it.  ChatGPT, \"tell me more about describe() in Python for summarizing dataframes.\"\n",
    "\n",
    "Then, I get a good explanation of describe(), although it does not mention the percentiles option.  One advantage of using Google or the documentation in addition of ChatGPT is that these sources may provide interesting information that does not directly answer our question.  Thus, we might not have known about the various arguments, such as percentiles, if we only used ChatGPT.  A second issue is that ChatGPT sometimes hallucinates (it makes up information).  In general, by examining multiple sources - Google, documentation, and ChatGPT - we can get more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e0e5f5",
   "metadata": {},
   "source": [
    "**<span style=\"color:green\"> Answer </span>**\n",
    "\n",
    "I have added: <br>\n",
    "print(df.info()) - summary, and structure; <br>\n",
    "print(df.describe()) - generates descriptive statistics for numeric columns; <br>\n",
    "print(df.head()) - displays the first 5 rows; <br>\n",
    "print(f\"Shape: {df.shape}\") - provides the dimensions of the DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cede07d-03a8-4c36-b5ca-67619bbfd365",
   "metadata": {},
   "source": [
    "# 2. Weekly graph question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a71d462-12df-4b94-b34f-4d43e4d289d7",
   "metadata": {},
   "source": [
    "In Storytelling With Data, on page 1: examine the pie chart graph in the upper left corner of the graphs.  Please write a short explanation of the pros and cons of this graph.  What do you think of the choice of pie chart as a format?  The color scheme?  The legend?  The title?  How would you draw it differently if you were creating this graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cb9199",
   "metadata": {},
   "source": [
    "<img src=\"Survey Results.png\" alt=\"Pie Chart\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236fff3e",
   "metadata": {},
   "source": [
    "\n",
    "**<span style=\"color:green\"> Answer </span>**\n",
    "\n",
    "**Pros**  \n",
    "1. **Clear Title:** The title \"Survey Results\" clearly indicates the chart’s purpose.  \n",
    "2. **Simple Representation:** Pie charts effectively show parts of a whole.  \n",
    "3. **Percentage Labels:** Including percentages helps readers quickly understand the data distribution.\n",
    "\n",
    "**Cons**  \n",
    "1. **Choice of Pie Chart:** Pie charts are not effective for comparing close values, like 19% versus 25%.  \n",
    "2. **Color Scheme:** Colors are distinct, but may pose accessibility issues for those with color vision deficiencies.  \n",
    "3. **Legend Placement:** The legend's position requires viewers to constantly shift their gaze, making it harder to match slices with categories.  \n",
    "4. **Title Specificity:** The title is too generic and lacks context; a more specific title would improve clarity.\n",
    "\n",
    "**Suggested Improvements**  \n",
    "1. **Use a Different Chart Type:** Consider a bar chart for better comparison of similar values.  \n",
    "2. **Improve the Color Scheme:** Use a colorblind-friendly palette with thematic colors.  \n",
    "3. **Add Labels Directly:** Place category names on or near the slices for easier identification.  \n",
    "4. **Make the Title More Informative:** A descriptive title, like \"Survey Results on Audience Engagement,\" would enhance understanding.\n",
    "\n",
    "**How I Would Redraw It**  \n",
    "1. **Use a Horizontal Bar Chart:** This allows for clearer comparisons.  \n",
    "2. **Add Data Labels:** Show category names and percentages directly on the bars.  \n",
    "3. **Choose a Colorblind-Friendly Palette:** Group sentiments like \"Positive\" and \"Negative.\"  \n",
    "4. **Provide a Subtitle:** Add context about the survey, such as \"Survey on Audience Reactions to Event X.\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a54048-d621-47b9-aa65-4b46d9c3bb4c",
   "metadata": {},
   "source": [
    "# 3. Homework - Bank Customers\n",
    "\n",
    "I will begin by creating a file for you to analyze.  I will show you all of the steps I used to create it.  Please run this code in order to create and save a file about bank customers.\n",
    "\n",
    "### The numbered problems are for you to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "2950b5f1-9ab8-452f-b9d7-31ce82bbf698",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_customers = 100\n",
    "np.random.seed(0) # Random numbers (same every time you run the code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "95561d16-3aac-4537-841a-835272775080",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bank = pd.DataFrame(columns = [\"CustomerID\"]) # creates an empty DataFrame with a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "3e84ff91-47c6-4788-b56b-1d63a2b06a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This generates a range of numbers from 0 to num_customers - 1.\n",
    "# If num_customers = 100, it creates an array: [0, 1, 2, ..., 99].\n",
    "df_bank[\"CustomerID\"] = [str(x) for x in np.arange(num_customers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "5983f3fb-8341-4bb0-92be-850dd712c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These define the start and end dates for generating random birthdates.\n",
    "start = datetime(1950, 1, 1)\n",
    "end = datetime(2024, 1, 1)\n",
    "# This calculates the difference between the two dates in days.\n",
    "numdays = (end - start).days\n",
    "# Generates an array of num_customers random integers between 0 and numdays - 1.\n",
    "random_days = np.random.randint(0, numdays, size = num_customers)\n",
    "# Formats the birthdates into the YYYY-MM-DD format (e.g., \"1985-03-14\").\n",
    "df_bank[\"BirthDate\"] = start + pd.to_timedelta(random_days, unit='D')\n",
    "df_bank[\"BirthDate\"] = df_bank[\"BirthDate\"].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "64adeb78-6b2c-46df-a4f0-8aee5fa75f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ssn_string(num):\n",
    "    # Convert to a 9-digit string.\n",
    "    ssn_str = f'{num:09}'\n",
    "    # ssn_str[0:3]: Extracts the first 3 characters (area number).\n",
    "    # ssn_str[3:5]: Extracts the next 2 characters (group number).\n",
    "    # ssn_str[5:9]: Extracts the last 4 characters (serial number).\n",
    "    return ssn_str[0:3] + \"-\" + ssn_str[3:5] + \"-\" + ssn_str[5:9]\n",
    "ssn_vector_func = np.vectorize(make_ssn_string)\n",
    "# Generating Random SSNs\n",
    "df_bank[\"SSN\"] = ssn_vector_func(np.random.randint(0, 999999999, size = num_customers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "0a8e00bb-2f97-4e11-a95f-138baf44206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line adds a new column named \"AccountID\" to the df_bank DataFrame. \n",
    "# The values in this column are randomly generated integers within a specified range\n",
    "df_bank[\"AccountID\"] = np.random.randint(0, num_customers, size = num_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "bc41db6c-9e4a-4efc-af0d-9f921bb77ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This generates an array of random integers between 0 and 365 * 80 (the total number of days in 80 years).\n",
    "random_days = np.random.randint(0, 365 * 80, size = num_customers)\n",
    "df_bank[\"AccountOpened\"] = (pd.to_datetime(df_bank[\"BirthDate\"]) + pd.to_timedelta(random_days, unit='D')).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "cd2ddf02-7ef2-485a-8d1a-1049b30630dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accesses the value in the row with index 0 and the column \"BirthDate\" and changes it to \"1980\".\n",
    "df_bank.loc[0, \"BirthDate\"] = \"1980\"\n",
    "# Accesses the value in the row with index 1 and the column \"BirthDate\" and changes it to \"no date\".\n",
    "df_bank.loc[1, \"BirthDate\"] = \"no date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "e5e52d8f-10b5-433f-bcfa-9d50232041e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accesses the value in the row with index 2 and the column \"AccountID\" and changes it to NaN.\n",
    "df_bank.loc[2, \"AccountID\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "bdb0d5e7-1bcb-48f0-ab70-c7c3d4b8bfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line adds a new column named \"AccountType\" to the df_bank DataFrame. \n",
    "# The values in this column are randomly assigned from the list \n",
    "# [\"checking\", \"savings\", \"cd\"] for each custome\n",
    "df_bank[\"AccountType\"] = np.random.choice([\"checking\", \"savings\", \"cd\"], size = num_customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314a2bef-d599-4599-b555-7a01c2cd3fb3",
   "metadata": {},
   "source": [
    "Load the bank_customers.csv file.  (There is no practical reason to save it, then load it - we're just demonstrating how this would be done.)\n",
    "I am calling the loaded df by a new name, df_bank_loaded, to make clear why it's not the same variable as the old df.  Of course, in actuality the two contain the exact same data!  But it's good to get in the habit of naming things carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "15dea7e7-619d-4d3f-aa72-712f3da7d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying a Row from One DataFrame to Another\n",
    "df_bank.loc[num_customers - 1] = df.loc[0]\n",
    "# Saving the Updated DataFrame to a CSV File\n",
    "df_bank.to_csv(\"bank_customers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "faf79336-ba67-446e-8220-e77534c4c949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID   BirthDate          SSN  AccountID AccountOpened AccountType\n",
      "0         0.0        1980  155-38-1177       88.0    2008-03-23    checking\n",
      "1         1.0     no date  617-74-2429       70.0    1979-09-15     savings\n",
      "2         2.0  2003-02-20  779-07-4907        NaN    2060-08-14    checking\n",
      "3         3.0  1995-03-02  641-93-8833        6.0    2017-10-18     savings\n",
      "4         4.0  1955-05-22  118-52-4323       28.0    2018-05-29     savings\n",
      "    CustomerID   BirthDate          SSN  AccountID AccountOpened AccountType\n",
      "95        95.0  1952-04-07  422-95-9804       51.0    2028-09-01    checking\n",
      "96        96.0  1977-06-29  513-19-9342       49.0    1998-01-10     savings\n",
      "97        97.0  2013-07-27  395-25-5461       71.0    2026-08-13    checking\n",
      "98        98.0  1978-07-06  876-87-0827       90.0    2038-10-24     savings\n",
      "99         NaN         NaN          NaN        NaN           NaN         NaN\n",
      "       CustomerID  AccountID\n",
      "count   99.000000  98.000000\n",
      "mean    49.000000  48.510204\n",
      "std     28.722813  28.140753\n",
      "min      0.000000   1.000000\n",
      "25%     24.500000  25.000000\n",
      "50%     49.000000  49.000000\n",
      "75%     73.500000  71.750000\n",
      "max     98.000000  97.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   CustomerID     99 non-null     float64\n",
      " 1   BirthDate      99 non-null     object \n",
      " 2   SSN            99 non-null     object \n",
      " 3   AccountID      98 non-null     float64\n",
      " 4   AccountOpened  99 non-null     object \n",
      " 5   AccountType    99 non-null     object \n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 4.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Reads a CSV file and stores it in a DataFrame\n",
    "df_bank_loaded = pd.read_csv(\"bank_customers.csv\")\n",
    "# Displays the first 5 rows of the DataFrame\n",
    "print(df_bank_loaded.head())\n",
    "# Displays the last 5 rows of the DataFrame\n",
    "print(df_bank_loaded.tail())\n",
    "# Describes the DataFrame\n",
    "print(df_bank_loaded.describe())\n",
    "# Information about the DataFrame\n",
    "print(df_bank_loaded.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380145bb-e051-418d-b3d2-ad032cab375b",
   "metadata": {},
   "source": [
    "1. Use describe() and info() to analyze the data.   Also, look at the first few rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8897936c-9af9-4344-bdb7-6290d8b34bce",
   "metadata": {},
   "source": [
    "Suggested Google Search or ChatGPT prompt: \"how do I use the describe function in python\"\n",
    "\n",
    "Example Google result: https://www.w3schools.com/python/pandas/ref_df_describe.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "5fb74ed3-871e-41b6-99f5-da7eb3a37712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   CustomerID     99 non-null     float64       \n",
      " 1   BirthDate      99 non-null     object        \n",
      " 2   SSN            99 non-null     object        \n",
      " 3   AccountID      98 non-null     float64       \n",
      " 4   AccountOpened  99 non-null     datetime64[ns]\n",
      " 5   AccountType    99 non-null     object        \n",
      "dtypes: datetime64[ns](1), float64(2), object(3)\n",
      "memory usage: 4.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# The first few rows\n",
    "df_bank_loaded.iloc[0:5]\n",
    "# Describe the DataFrame\n",
    "df_bank_loaded.describe()\n",
    "# Information about the DataFrame\n",
    "df_bank_loaded.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6062d1d-bf7f-4e81-8d19-60bd160c02d5",
   "metadata": {},
   "source": [
    "If you used describe() and info(), you now know that BirthDate and AccountOpened are strings.  But we want them to be dates.  Let's convert them to dates (or Timestamps in pandas).  When we try this, we get a ValueError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "89e37c09-aee4-49f5-abc5-1e6ec9837b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError for BirthDate: time data \"1980\" doesn't match format \"%Y-%m-%d\", at position 0. You might want to try:\n",
      "    - passing `format` if your strings have a consistent format;\n",
      "    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # This line converts the \"BirthDate\" column to a datetime object.\n",
    "    df_bank_loaded[\"BirthDate\"] = pd.to_datetime(df_bank_loaded[\"BirthDate\"], format='%Y-%m-%d')\n",
    "    print(\"It worked!\")\n",
    "    # Handle any errors\n",
    "except ValueError as e:\n",
    "    print(f\"ValueError for BirthDate: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "dbcb584b-134b-475b-8fd4-70ca1ba7d03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It worked!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Converts the \"AccountOpened\" column into pandas datetime objects\n",
    "    df_bank_loaded[\"AccountOpened\"] = pd.to_datetime(df_bank_loaded[\"AccountOpened\"], format='%Y-%m-%d')\n",
    "    print(\"It worked!\")\n",
    "    # Handle any errors\n",
    "except ValueError as e:\n",
    "    print(f\"ValueError for AccountOpened: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64b1ccf-1001-40ab-b026-beae68b7fd19",
   "metadata": {},
   "source": [
    "The simple way to fix this is to remove the rows that have bad dates for BirthDate.  I Googled:\n",
    "\n",
    "\"How to remove rows from a dataframe that have poorly formatted dates using python\"\n",
    "\n",
    "https://stackoverflow.com/questions/21556744/pandas-remove-rows-whose-date-does-not-follow-specified-format\n",
    "\n",
    "This recommends that I verify that the date is a string of length 10, because YYYY-MM-DD has that length:\n",
    "\n",
    "df1\\[df1.BirthDate.str.len() !=10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "70ec53a1-2de5-48b5-9942-6857495e2b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code evaluates how many rows in the df_bank_loaded DataFrame \n",
    "# have a \"BirthDate\" value with exactly 10 characters\n",
    "len(df_bank_loaded[df_bank_loaded.BirthDate.str.len() == 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "a4edac07-185c-45ad-ba95-cca56bca0c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>BirthDate</th>\n",
       "      <th>SSN</th>\n",
       "      <th>AccountID</th>\n",
       "      <th>AccountOpened</th>\n",
       "      <th>AccountType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1980</td>\n",
       "      <td>155-38-1177</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2008-03-23</td>\n",
       "      <td>checking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>no date</td>\n",
       "      <td>617-74-2429</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1979-09-15</td>\n",
       "      <td>savings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CustomerID BirthDate          SSN  AccountID AccountOpened AccountType\n",
       "0          0.0      1980  155-38-1177       88.0    2008-03-23    checking\n",
       "1          1.0   no date  617-74-2429       70.0    1979-09-15     savings\n",
       "99         NaN       NaN          NaN        NaN           NaT         NaN"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code filters the df_bank_loaded DataFrame to find rows where the length of the \n",
    "# \"BirthDate\" string is not equal to 10, and then retrieves the first 5 such rows\n",
    "df_bank_loaded[df_bank_loaded.BirthDate.str.len() != 10].iloc[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2503d01f-0168-43f9-a271-6f529e47886f",
   "metadata": {},
   "source": [
    "Now we can make this permanent, creating a new DataFrame df_bank_datefix.\n",
    "I am making a copy in order to ensure that df_bank_datefix is a new DataFrame rather than being a slice of the old one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "d1bed857-0d03-4091-9838-fd75227c63e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code filters the df_bank_loaded DataFrame to include only \n",
    "# rows where the \"BirthDate\" column contains strings with a length of \n",
    "# exactly 10 characters (e.g., dates in the format YYYY-MM-DD). \n",
    "# The filtered result is copied into a new DataFrame called df_bank_datefix\n",
    "df_bank_datefix = df_bank_loaded[df_bank_loaded.BirthDate.str.len() == 10].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838e568e-a333-4d18-ba8d-84c2926191e8",
   "metadata": {},
   "source": [
    "Test again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "d8655d6a-0a79-42c4-891a-cb421d664ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It worked!\n"
     ]
    }
   ],
   "source": [
    "# This code tries to convert the \"BirthDate\" column in the df_bank_datefix DataFrame \n",
    "# into datetime objects using the specified format '%Y-%m-%d'.\n",
    "try:\n",
    "    df_bank_datefix[\"BirthDate\"] = pd.to_datetime(df_bank_datefix[\"BirthDate\"], format='%Y-%m-%d')\n",
    "    print(\"It worked!\")\n",
    "except ValueError as e:\n",
    "    print(f\"ValueError: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa88b739-9481-46fd-a8bd-996ed0e0bc2f",
   "metadata": {},
   "source": [
    "2. To check that it worked, use a summary function that will tell you if the BirthDate field is now a datetime type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "ce550219-274c-4e3c-953d-cdf920a37990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 97 entries, 2 to 98\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   CustomerID     97 non-null     float64       \n",
      " 1   BirthDate      97 non-null     datetime64[ns]\n",
      " 2   SSN            97 non-null     object        \n",
      " 3   AccountID      96 non-null     float64       \n",
      " 4   AccountOpened  97 non-null     datetime64[ns]\n",
      " 5   AccountType    97 non-null     object        \n",
      "dtypes: datetime64[ns](2), float64(2), object(2)\n",
      "memory usage: 5.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_bank_datefix.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ac0d0-be31-4c50-838d-f104463a8114",
   "metadata": {},
   "source": [
    "3. Check whether there are any null values in the DataFrame.  If so, remove those rows or (if you prefer) fill in the value with an appropriate number.\n",
    "\n",
    "First try at a Google search or ChatGPT prompt: \"how do I find out if there are any null values in a pandas DataFrame?\"\n",
    "\n",
    "This page gives an answer.  Unfortunately, it took my request too literally: it tells me only if there are any, and not which rows have them.  On reflection, that's not really what I want - I think I asked the wrong question.  I want to see the rows, not just _whether_ there are any.\n",
    "\n",
    "https://stackoverflow.com/questions/29530232/how-to-check-if-any-value-is-nan-in-a-pandas-dataframe\n",
    "\n",
    "ChatGPT likewise doesn't give the answer I want - because I asked the wrong question.\n",
    "\n",
    "Next try at a Google search or ChatGPT prompt: \"how do I check which rows have null values in a pandas DataFrame?\"\n",
    "\n",
    "This page gives an answer:\n",
    "\n",
    "https://stackoverflow.com/questions/36226083/how-to-find-which-columns-contain-any-nan-value-in-pandas-dataframe\n",
    "\n",
    "ChatGPT also gives a good answer.  I recommend looking at both of them!\n",
    "\n",
    "Now try it on your own:\n",
    "\n",
    "Suggested Google search or ChatGPT prompt: \"how do I remove rows with null values in a pandas DataFrame?\"\n",
    "\n",
    "Suggested Google search or ChatGPT prompt: \"how do I fill in null values in a pandas DataFrame?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "a8ffaf2e-a8b2-42a2-ad09-e014431fccea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID       False\n",
      "BirthDate        False\n",
      "SSN              False\n",
      "AccountID         True\n",
      "AccountOpened    False\n",
      "AccountType      False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(df_bank_datefix.isna().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ca88fe-0b67-473e-965f-7e5da13f2a02",
   "metadata": {},
   "source": [
    "4. Find out if there are any duplicate rows (two rows exactly the same).  List their row numbers.  Then remove the duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abf0983-4861-486b-bfc0-942b6772c866",
   "metadata": {},
   "source": [
    "Suggested Google search or ChatGPT prompt: \"how can I find out if there are any duplicate rows in a DataFrame using Python\"\n",
    "\n",
    "Again, Google provides me with a page that addresses the question:\n",
    "\n",
    "https://saturncloud.io/blog/how-to-find-all-duplicate-rows-in-a-pandas-dataframe/\n",
    "\n",
    "To remove the duplicates, do this search: \"how can I remove the duplicate rows in a DataFrame using Python\"\n",
    "\n",
    "This leads me to the following documentation.\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "acd1cc2f-2879-4839-8ac7-9b2bc306dfb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>BirthDate</th>\n",
       "      <th>SSN</th>\n",
       "      <th>AccountID</th>\n",
       "      <th>AccountOpened</th>\n",
       "      <th>AccountType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2003-02-20</td>\n",
       "      <td>779-07-4907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2060-08-14</td>\n",
       "      <td>checking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1995-03-02</td>\n",
       "      <td>641-93-8833</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2017-10-18</td>\n",
       "      <td>savings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1955-05-22</td>\n",
       "      <td>118-52-4323</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2018-05-29</td>\n",
       "      <td>savings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1996-08-21</td>\n",
       "      <td>168-46-4066</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2028-05-10</td>\n",
       "      <td>cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1961-11-12</td>\n",
       "      <td>553-45-1924</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1978-04-24</td>\n",
       "      <td>checking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94.0</td>\n",
       "      <td>1962-05-22</td>\n",
       "      <td>838-81-3699</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2025-12-15</td>\n",
       "      <td>savings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95.0</td>\n",
       "      <td>1952-04-07</td>\n",
       "      <td>422-95-9804</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2028-09-01</td>\n",
       "      <td>checking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96.0</td>\n",
       "      <td>1977-06-29</td>\n",
       "      <td>513-19-9342</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1998-01-10</td>\n",
       "      <td>savings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97.0</td>\n",
       "      <td>2013-07-27</td>\n",
       "      <td>395-25-5461</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2026-08-13</td>\n",
       "      <td>checking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98.0</td>\n",
       "      <td>1978-07-06</td>\n",
       "      <td>876-87-0827</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2038-10-24</td>\n",
       "      <td>savings</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    CustomerID  BirthDate          SSN  AccountID AccountOpened AccountType\n",
       "2          2.0 2003-02-20  779-07-4907        NaN    2060-08-14    checking\n",
       "3          3.0 1995-03-02  641-93-8833        6.0    2017-10-18     savings\n",
       "4          4.0 1955-05-22  118-52-4323       28.0    2018-05-29     savings\n",
       "5          5.0 1996-08-21  168-46-4066        6.0    2028-05-10          cd\n",
       "6          6.0 1961-11-12  553-45-1924       66.0    1978-04-24    checking\n",
       "..         ...        ...          ...        ...           ...         ...\n",
       "94        94.0 1962-05-22  838-81-3699       82.0    2025-12-15     savings\n",
       "95        95.0 1952-04-07  422-95-9804       51.0    2028-09-01    checking\n",
       "96        96.0 1977-06-29  513-19-9342       49.0    1998-01-10     savings\n",
       "97        97.0 2013-07-27  395-25-5461       71.0    2026-08-13    checking\n",
       "98        98.0 1978-07-06  876-87-0827       90.0    2038-10-24     savings\n",
       "\n",
       "[97 rows x 6 columns]"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank_datefix.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5cd8a5-c8bd-498c-b8b5-25dd74cdd2c6",
   "metadata": {},
   "source": [
    "5. Check whether the customers all have unique AccountIDs.  If not, provide the first example of a non-unique AccountId."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4f3f46-b09e-4a48-a3f4-72e1d1ba77fc",
   "metadata": {},
   "source": [
    "Suggested Google search or ChatGPT prompt: \"how can I find the first non-unique item from a pandas Series in python\"\n",
    "\n",
    "By the way: why didn't I ask the question \"how can I check whether the customers all have unique AccountIDs\"?\n",
    "\n",
    "The problem would be that Google and ChatGPT don't know what \"customers\" you are talking about.  It's important to understand that the AccountIDs are a column of a DataFrame, and as such they are a Series.  Therefore, we should use the correct vocabulary and ask about a Series.  If you mess up and ask about a \"list\" instead of a Series, you _might_ get an answer that still works.  But it's better to get the vocabularly right.\n",
    "\n",
    "It's important to add \"in python\" because this task could be performed in many languages.\n",
    "\n",
    "ChatGPT gave me this suggestion: data[data.isin(data[data.duplicated()])].iloc[0]\n",
    "However, ChatGPT did not explain how this code worked and even claimed (falsely) that it was going to use the value_counts() function in the solution.  So although the code is correct, I personally found ChatGPT's answer very confusing.  You could, perhaps, ask ChatGPT to explain further how this code works.\n",
    "\n",
    "ChatGPT, \"How does this code work: data[data.isin(data[data.duplicated()])].iloc[0]\"\n",
    "\n",
    "On the other hand, Google leads me to the documentation for the duplicated() function:\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.Series.duplicated.html\n",
    "\n",
    "Here, I can see that when I really need is data.duplicated(keep = False), where \"data\" should be the Series in question.  However, this just gives me a Series of boolean values indicating which ones are duplicates.  I have to somehow know that extracting the numerical values instead of a Series of booleans involves boolean indexing: data\\[data.duplicated(keep = False)].\n",
    "\n",
    "So as usual, I'd suggest that a combination of Google, documentation, and ChatGPT will give you the best information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "d3825ba0-a790-42e0-94ad-df931dbad3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate AccountIDs:\n",
      "    CustomerID  BirthDate          SSN  AccountID AccountOpened AccountType\n",
      "3          3.0 1995-03-02  641-93-8833        6.0    2017-10-18     savings\n",
      "5          5.0 1996-08-21  168-46-4066        6.0    2028-05-10          cd\n",
      "7          7.0 1953-10-16  325-06-3597       92.0    1963-08-29    checking\n",
      "8          8.0 1986-05-10  612-78-7385       92.0    1995-05-03     savings\n",
      "9          9.0 1987-12-20  631-41-9855       69.0    2002-02-06    checking\n",
      "10        10.0 1950-03-05  886-50-5847       73.0    1965-07-22          cd\n",
      "11        11.0 1960-12-13  686-63-6708       54.0    2005-11-19     savings\n",
      "13        13.0 2001-09-16  555-82-1758       21.0    2009-08-28          cd\n",
      "15        15.0 1985-04-18  338-96-9073       81.0    2002-12-13    checking\n",
      "18        18.0 1956-07-15  888-67-7790       25.0    2025-12-13          cd\n",
      "19        19.0 2022-05-27  689-53-4317       21.0    2042-09-25    checking\n",
      "20        20.0 2009-08-17  567-11-3559       45.0    2041-06-26    checking\n",
      "23        23.0 2023-07-07  216-37-3833       25.0    2093-03-22          cd\n",
      "24        24.0 1987-01-24  962-79-2666       37.0    1988-09-27     savings\n",
      "26        26.0 1965-10-12  640-05-8906        5.0    2036-01-21     savings\n",
      "28        28.0 1970-04-02  661-61-5638       12.0    1996-11-29    checking\n",
      "29        29.0 1960-09-03  757-22-7980       90.0    2016-10-11    checking\n",
      "31        31.0 1990-04-06  958-72-5474       54.0    2018-11-30    checking\n",
      "32        32.0 2014-11-01  857-37-0202       78.0    2088-11-17          cd\n",
      "35        35.0 1995-08-29  928-76-1646       71.0    2066-10-13     savings\n",
      "36        36.0 2019-07-31  029-11-4064       45.0    2051-03-18    checking\n",
      "37        37.0 1989-08-14  116-26-0413        5.0    2014-07-28     savings\n",
      "46        46.0 1952-01-07  893-94-9446        3.0    2021-10-27          cd\n",
      "47        47.0 2023-07-29  014-72-0685       78.0    2044-09-15     savings\n",
      "48        48.0 1962-03-20  390-77-4005       82.0    1993-09-11    checking\n",
      "49        49.0 2000-04-03  874-97-6670       69.0    2038-06-10          cd\n",
      "50        50.0 1981-05-23  462-66-5231       58.0    2027-01-10    checking\n",
      "51        51.0 1987-08-24  248-29-7641        4.0    2020-04-14    checking\n",
      "53        53.0 1986-03-10  418-62-4821       69.0    2030-03-22    checking\n",
      "56        56.0 2000-08-30  325-34-8743       24.0    2045-07-09     savings\n",
      "57        57.0 1984-04-26  485-42-8444        3.0    2057-08-03    checking\n",
      "58        58.0 2014-01-05  303-94-2465       69.0    2072-01-08    checking\n",
      "61        61.0 2023-06-24  281-42-2684       58.0    2052-09-20    checking\n",
      "62        62.0 1993-05-10  365-07-6814       49.0    2071-09-12     savings\n",
      "64        64.0 2004-02-26  405-69-3659       24.0    2074-09-08          cd\n",
      "65        65.0 1967-02-07  553-61-4582       33.0    1972-11-05    checking\n",
      "66        66.0 2016-10-25  573-84-1508       18.0    2056-09-23    checking\n",
      "68        68.0 2018-12-01  855-97-6157       78.0    2024-07-30     savings\n",
      "69        69.0 1964-08-18  269-35-0066        7.0    1983-04-28     savings\n",
      "71        71.0 1982-08-10  747-46-2830       46.0    2055-11-07    checking\n",
      "72        72.0 1959-05-13  847-73-3341       33.0    1974-09-15          cd\n",
      "73        73.0 1953-02-05  037-29-7778       81.0    2015-10-11          cd\n",
      "75        75.0 2000-05-05  425-36-6284       12.0    2021-11-25     savings\n",
      "76        76.0 1977-12-18  143-04-2281       46.0    2045-11-12    checking\n",
      "80        80.0 1976-10-05  452-55-5763       25.0    2017-07-03          cd\n",
      "81        81.0 1972-06-06  832-70-2589       46.0    2045-09-26     savings\n",
      "84        84.0 1987-12-15  070-13-0394       76.0    2065-10-03          cd\n",
      "85        85.0 2001-10-31  136-79-1195       73.0    2002-07-24          cd\n",
      "86        86.0 1957-05-07  795-56-6776       18.0    1988-03-15    checking\n",
      "87        87.0 2018-03-24  409-55-8136        4.0    2032-12-17          cd\n",
      "88        88.0 1992-04-26  649-65-4593        7.0    2016-06-05          cd\n",
      "89        89.0 1969-02-25  155-79-7952        3.0    2047-05-29          cd\n",
      "90        90.0 2013-08-24  770-05-0757       48.0    2048-03-12          cd\n",
      "91        91.0 1966-11-29  774-25-4424       76.0    2037-12-07          cd\n",
      "92        92.0 1968-01-25  427-84-2850       37.0    2044-10-22          cd\n",
      "93        93.0 1966-05-22  468-91-4127       48.0    2017-11-12     savings\n",
      "94        94.0 1962-05-22  838-81-3699       82.0    2025-12-15     savings\n",
      "96        96.0 1977-06-29  513-19-9342       49.0    1998-01-10     savings\n",
      "97        97.0 2013-07-27  395-25-5461       71.0    2026-08-13    checking\n",
      "98        98.0 1978-07-06  876-87-0827       90.0    2038-10-24     savings\n"
     ]
    }
   ],
   "source": [
    "# Identify all duplicate AccountIDs\n",
    "duplicate_rows = df_bank_datefix[df_bank_datefix[\"AccountID\"].duplicated(keep=False)]\n",
    "print(\"Duplicate AccountIDs:\")\n",
    "print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed68b682-fb52-4c2d-a172-5a76aa31395b",
   "metadata": {},
   "source": [
    "6. Count how many distinct AccountIDs there are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754c31c5-e1d2-4387-bbe8-d156e731483a",
   "metadata": {},
   "source": [
    "Suggested Google search or ChatGPT prompt: \"how can I find out how many distinct items there are in a pandas Series using python\"\n",
    "\n",
    "This time Google provides me with a page that's specifically made to answer this question:\n",
    "\n",
    "https://www.geeksforgeeks.org/how-to-count-distinct-values-of-a-pandas-dataframe-column/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "3a5c497f-acca-4bea-b693-9e628ce40c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct AccountIDs (including NaN): 64\n"
     ]
    }
   ],
   "source": [
    "distinct_account_ids_with_nan = df_bank_datefix[\"AccountID\"].nunique(dropna=False)\n",
    "print(f\"Number of distinct AccountIDs (including NaN): {distinct_account_ids_with_nan}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85058f11-6222-4511-92f6-537be74c4807",
   "metadata": {},
   "source": [
    "7. Remove the duplicate AccountIDs so that each AccountID appears only once.\n",
    "\n",
    "This will involve using data.duplicated() but this time without keep = False.  We don't want to drop all duplicates; we want to leave one example of each value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d904a7ec-a21c-498b-bd1c-1b8415a48f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3b55f40-7b54-462c-82a5-05960d970365",
   "metadata": {},
   "source": [
    "8. What are the mean, median, and mode customer age in years?  (Rounding down to the next lower age.)\n",
    "Are there any outliers?  (Customers with very large or very small ages, compared with the other ages?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b8cb00-e676-4b21-9211-06f26edf5a61",
   "metadata": {},
   "source": [
    "Suggested Google search or ChatGPT prompt: \"how can I find out the mean, median, and mode of a pandas Series\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cc3e88-aa16-4748-bf2d-b4c9672c7170",
   "metadata": {},
   "source": [
    "9. One-hot encode the AccountType column.  This means creating a new \"checking,\" \"savings\", and \"cd\" columns so that you can run machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "3ef9c041-9c44-4130-beec-c701ca1117a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[393], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m one_hot \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(df1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccountType\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      2\u001b[0m df2 \u001b[38;5;241m=\u001b[39m df2\u001b[38;5;241m.\u001b[39mjoin(one_hot)\n\u001b[1;32m      3\u001b[0m df2\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m5\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "one_hot = pd.get_dummies(df1[\"AccountType\"])\n",
    "df2 = df2.join(one_hot)\n",
    "df2.iloc[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55874415-e923-4179-86ea-502458cbcd7e",
   "metadata": {},
   "source": [
    "Now, change the cd, checking, and savings columns into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edda21a5-bb8c-4824-b320-1416dd807fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e884d3e-1d76-42a2-9b2e-86471286aa51",
   "metadata": {},
   "source": [
    "10. Are there any other data values that do not seem right?  If not, give an example?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c08a456-ae6d-4c79-8ca6-41f28d5cff20",
   "metadata": {},
   "source": [
    "I don't think Google or ChatGPT alone will help you here.  To answer the question, look at the columns and think about what relationships they should have with each other.  For example, it seems reasonable to expect that BirthDate would be no earlier than 120 years ago (it's unlikely that a customer would be this old.)  Now we can ask Google:\n",
    "\n",
    "\"How can I find out how long ago a pandas date is\"\n",
    "\n",
    "Google provides this helpful link, although it is not exactly the solution - you'll have to work with it a bit:\n",
    "\n",
    "https://stackoverflow.com/questions/26072087/pandas-number-of-days-elapsed-since-a-certain-date\n",
    "\n",
    "If you check, I think you'll find that all dates are more recent than 120 years ago.  What about the AccountOpened columns?  I see some obviously wrong dates there just by looking at the first few rows.\n",
    "\n",
    "Along those same lines, are there any birth dates that are too recent?  Do we think that any two year olds will have opened bank accounts?  How common do you think this is in real life?  How common is it in our data set?  Can you detect the two year olds opening bank accounts using just one column, or do you need two columns?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63be984a-21d0-43e7-8a55-fb8a67b8a351",
   "metadata": {},
   "source": [
    "11. Use Matplotlib and/or Seaborn to analyse the ages at which customers open their account.  Is there a connection between the year they are born vs. the age at which they open the account?  Graph this in whatever way you think is best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84574af6-9f3a-481a-843a-877388973ef2",
   "metadata": {},
   "source": [
    "I asked Google and ChatGPT: \"How can I plot dates vs. dates in Matplotlib\".  This gave me a hard time at first - I had to tell ChatGPT it was giving me the wrong information because it tried to plot dates vs. numbers.  Eventually, I found out that you plot dates vs. dates in the same way you'd plot numbers vs. numbers.\n",
    "\n",
    "Think in terms of Storytelling With Data to plot these as best you can.  Once you've seen the result, try to think of the best way to plot the data so as to show the user what you want them to see.  Title the graph so as to display the lesson that you want the user to take away.\n",
    "Here are some options for the axes:\n",
    "\n",
    "1. A scatter or line plot: On the x-axis, the date they are born.  On the y-axis, the date they open the account.\n",
    "2. A scatter or line plot: On the x-axis, the date they are born.  On the y-axis, the age in years at which they open the account.\n",
    "3. A scatter or line plot: On the x-axis, they year (integer) they are born.  On the y-axis, the age in years at which they open the account.\n",
    "4. A histogram: on the x-axis, the age at which they open the account.\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453acced-f7b1-4bb5-943d-716ae0505ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = plt.gca() # get an \"Axes\" object to draw on; gca stands for \"get current Axes\"\n",
    "ax.scatter(df2[\"BirthDate\"], df2[\"AccountOpened\"]) # create a scatter plot based on these two dates\n",
    "ax.set_ylabel(\"Account Opened\") # label the y axis\n",
    "ax.set_xlabel(\"Birth Date\") # label the x axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d2ca82-ea81-46e5-9002-8321987d08d9",
   "metadata": {},
   "source": [
    "# 4. Storytelling With Data graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00e6940-4a0c-4b3e-93dd-460239bf9940",
   "metadata": {},
   "source": [
    "Choose any graph in the Introduction of Storytelling With Data.  Using matplotlib to reproduce it in a rough way.  I don't expect you to spend an enormous amount of time on this; I understand that you likely will not have time to re-create every feature of the graph.  However, if you're excited about learning to use matplotlib, this is a good way to do that.  You don't have to duplicate the exact values on the graph; just the same rough shape will be enough.  If you don't feel comfortable using matplotlib yet, do the best you can and write down what you tried or what Google searches you did to find the answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c023ff6f-f3c8-4df7-a7a6-191e70bcb362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
